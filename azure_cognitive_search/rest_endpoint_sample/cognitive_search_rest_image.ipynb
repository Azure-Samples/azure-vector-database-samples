{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search on Image: Azure Cognitive Search via REST Endpoint\n",
    "\n",
    "This notebook demonstrates how to use Azure Cognitive Search REST endpoint with OpenAI to work with images. It uses the [image](../../data/image) as source dataset. \n",
    "\n",
    "Key steps in the notebook -\n",
    "\n",
    "- Create ACS Index from index definition via REST endpoint\n",
    "- Load the source dataset and generating embeddings\n",
    "- Ingesting embeddings to ACS Index via REST endpoint\n",
    "- Multiple search queries\n",
    "  \n",
    "### Prerequisites\n",
    "\n",
    "- Create a conda environment using the [cognitive_search_rest_conda.yml](/cognitive_search_rest_conda.yml) file to include all the python dependencies.\n",
    "- Create a *.env* file from the *.env-template* and populate it with all necessary endpoint links and keys. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "acs_endpoint = os.getenv(\"COGNITIVE_SEARCH_ENDPOINT\")\n",
    "if acs_endpoint is None or acs_endpoint == \"\":\n",
    "    print(\"COGNITIVE_SEARCH_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "acs_index  = os.getenv(\"COGNITIVE_SEARCH_INDEX\")\n",
    "if acs_index is None or acs_index == \"\":\n",
    "    print(\"COGNITIVE_SEARCH_INDEX environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "acs_key  = os.getenv(\"COGNITIVE_SEARCH_KEY\")\n",
    "if acs_key is None or acs_key == \"\":\n",
    "    print(\"COGNITIVE_SEARCH_KEY environment variable not set.\")\n",
    "    exit()\n",
    "    \n",
    "acs_api_version  = os.getenv(\"COGNITIVE_SEARCH_API_VERSION\")\n",
    "if acs_api_version is None or acs_api_version == \"\":\n",
    "    print(\"COGNITIVE_SEARCH_API_VERSION environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_endpoint  = os.getenv(\"COMPUTER_VISION_ENDPOINT\")\n",
    "if com_vision_endpoint is None or com_vision_endpoint == \"\":\n",
    "    print(\"COMPUTER_VISION_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_key  = os.getenv(\"COMPUTER_VISION_KEY\")\n",
    "if com_vision_key is None or com_vision_key == \"\":\n",
    "    print(\"COMPUTER_VISION_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_endpoint  = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "if aoai_endpoint is None or aoai_endpoint == \"\":\n",
    "    print(\"AZURE_OPENAI_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_key  = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "if aoai_key is None or aoai_key == \"\":\n",
    "    print(\"AZURE_OPENAI_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_api_version  = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "if aoai_api_version is None or aoai_api_version == \"\":\n",
    "    print(\"AZURE_OPENAI_API_VERSION environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_embedding_deployed_model  = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL\")\n",
    "if aoai_embedding_deployed_model is None or aoai_embedding_deployed_model == \"\":\n",
    "    print(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL environment variable not set.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def insert_record(acs_endpoint, acs_index, data, acs_key, acs_api_version):\n",
    "    url = f\"{acs_endpoint}/indexes/{acs_index}/docs/index?api-version={acs_api_version}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": acs_key\n",
    "    }    \n",
    "    response = requests.post(url, data=data, headers=headers)\n",
    "    print(response.status_code)\n",
    "    print(response.content)\n",
    "\n",
    "def create_index(acs_endpoint, json_content, acs_index, api_key, acs_api_version):\n",
    "    url = f\"{acs_endpoint}/indexes/{acs_index}?api-version={acs_api_version}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    response = requests.request('PUT', url, headers=headers, data=json_content)\n",
    "    print(response.status_code)\n",
    "    print(response.content)\n",
    "\n",
    "def vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query):\n",
    "    vectorize_text_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeText\"  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    } \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "    }  \n",
    "    data = {\n",
    "        'text':query\n",
    "    }\n",
    "\n",
    "    response = requests.post(vectorize_text_url, params=params, headers=headers, json=data)\n",
    "    query_vector = response.json()[\"vector\"]\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "def search_vector_similarity(query_vector, top_doc_count, acs_endpoint, acs_index,acs_key, acs_api_version):\n",
    "    url = f\"{acs_endpoint}/indexes/{acs_index}/docs/search?api-version={acs_api_version}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": acs_key\n",
    "    }\n",
    "\n",
    "    request_body = {\n",
    "        \"vectors\": [{\n",
    "            \"value\": query_vector,\n",
    "            \"fields\": \"image_vector\",\n",
    "            \"k\": top_doc_count\n",
    "        }],\n",
    "        \"select\": \"image\"\n",
    "    }\n",
    "    request_body = json.dumps(request_body)\n",
    "\n",
    "    response = requests.request('POST', url, headers=headers, data=request_body)\n",
    "\n",
    "    docs = [(item['image']) for item in response.json()['value']]\n",
    "\n",
    "    return docs\n",
    "\n",
    "def show_image(image_folder, image):\n",
    "    image_path = os.path.join(image_folder, image)\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ACS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_definition_path = 'index_definition_image.json'\n",
    "index_definition = read_json_file(index_definition_path)\n",
    "\n",
    "create_index(acs_endpoint, index_definition, acs_index, acs_key, acs_api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "image_folder = \"../../data/images\"\n",
    "image_list = os.listdir(image_folder)\n",
    "df = pd.DataFrame(columns=['image', 'image_vector'])\n",
    "for image_name in image_list:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "    with open(image_path, \"rb\") as binary_file:\n",
    "        binary_data = binary_file.read()\n",
    "        \n",
    "        vectorize_img_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeImage\"  \n",
    "\n",
    "        params = {  \n",
    "            \"api-version\": \"2023-02-01-preview\"  \n",
    "        } \n",
    "\n",
    "        headers = {  \n",
    "            \"Content-Type\": \"image/jpeg\",  \n",
    "            \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "        }  \n",
    "\n",
    "        response = requests.post(vectorize_img_url, params=params, headers=headers, data=binary_data)\n",
    "\n",
    "        df_row = {'image':image_name, 'image_vector':response.json()[\"vector\"]}\n",
    "        df = pd.concat([df, pd.DataFrame([df_row])], ignore_index=True)\n",
    "\n",
    "df['id'] = df.index\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest to Azure Cognitive Search\n",
    "\n",
    "This cell works because the dataframe and the ACS Index both have same columns. If the dataframe doesn't have the same columns (column names or numbers) as the ACS Index, add a preprocessing step to it to structure the dataframe according to the ACS columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "batch_size = 10\n",
    "total_records = df.shape[0]\n",
    "fields = df.columns.to_numpy()\n",
    "df['id'] = df['id'].astype(str)\n",
    "\n",
    "records = {\n",
    "    'value': []\n",
    "}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    record = {}\n",
    "    for field in fields:\n",
    "            record[field] = row[field]\n",
    "\n",
    "    records['value'].append(\n",
    "        record\n",
    "    )\n",
    "\n",
    "    if index % batch_size == 0 or (index+1 == total_records):\n",
    "        json_data = json.dumps(records)\n",
    "        print(json_data)\n",
    "        insert_record(acs_endpoint, acs_index, json_data, acs_key, acs_api_version)\n",
    "        records['value'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'flower with hand'\n",
    "\n",
    "query_vector = vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query)\n",
    "search_results = search_vector_similarity(query_vector, 1, acs_endpoint, acs_index,acs_key, acs_api_version)\n",
    "\n",
    "show_image(image_folder, search_results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
