{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pg_host  = os.getenv(\"POSTGRESQL_HOST\")\n",
    "if pg_host is None or pg_host == \"\":\n",
    "    print(\"POSTGRESQL_HOST environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_user  = os.getenv(\"POSTGRESQL_USERNAME\")\n",
    "if pg_user is None or pg_user == \"\":\n",
    "    print(\"POSTGRESQL_USERNAME environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_password  = os.getenv(\"POSTGRESQL_PASSWORD\")\n",
    "if pg_password is None or pg_password == \"\":\n",
    "    print(\"POSTGRESQL_PASSWORD environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "db_name  = os.getenv(\"POSTGRESQL_DATABASE\")\n",
    "if db_name is None or db_name == \"\":\n",
    "    print(\"POSTGRESQL_DATABASE environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "postgresql_params = {\n",
    "    \"host\": pg_host,\n",
    "    \"port\": \"5432\", \n",
    "    \"dbname\": db_name,\n",
    "    \"user\": pg_user,\n",
    "    \"password\": pg_password\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add vector extension\n",
    "\n",
    "The vector extension needs to be enabled in every database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute('CREATE EXTENSION IF NOT EXISTS vector;')\n",
    "        \n",
    "        print('Vector extension added.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "def create_table(table_name, table_schema):\n",
    "\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(f\"DROP TABLE IF  EXISTS {table_name} \")\n",
    "            cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({table_schema});\")\n",
    "\n",
    "            print(f\"Table {table_name} created.\")\n",
    "\n",
    "## Create text_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    title text,\n",
    "    content text,\n",
    "    category text,\n",
    "    title_vector VECTOR(1536),\n",
    "    content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "create_table(text_table_name, table_schema)\n",
    "\n",
    "## Create doc_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    chunk_content text,\n",
    "    chunk_content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "create_table(doc_table_name, table_schema)\n",
    "\n",
    "## Create image_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    image text,\n",
    "    image_vector VECTOR(1024)\n",
    " \"\"\"\n",
    "create_table(image_table_name, table_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest text sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_df = pd.read_json('../data/text/product_docs_embeddings.json')\n",
    "records = text_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {text_table_name}(id, title, content, category, title_vector, content_vector) VALUES(%s, %s, %s, %s, %s, %s)\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Text sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest doc sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_df = pd.read_json('../data/docs/employee_handbook_embeddings.json')\n",
    "records = doc_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {doc_table_name}(id, chunk_content, chunk_content_vector) VALUES(%s, %s, %s)\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Doc sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest image sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "image_df = pd.read_json('../data/images/images_embeddings.json')\n",
    "records = image_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {image_table_name}(id, image, image_vector) VALUES(%s, %s, %s)\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Image sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IVFFlat Index\n",
    "\n",
    "An IVFFlat index divides vectors into lists, and then searches a subset of those lists that are closest to the query vector. Details - https://github.com/pgvector/pgvector#ivfflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_query_suffix(row_count):\n",
    "    query_suffix = ''\n",
    "    if row_count >= 1000:\n",
    "        # Determine the number of lists based on the number of rows\n",
    "        if row_count <= 1000000:\n",
    "            lists = row_count / 1000\n",
    "        else:\n",
    "            lists = math.sqrt(row_count)\n",
    "        query_suffix = f\"WITH (lists = {int(lists)})\"  \n",
    "\n",
    "    return query_suffix\n",
    "\n",
    "# Create index for text_sample table \n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(f'SELECT count(*) FROM {text_table_name}')\n",
    "        row_count = cursor.fetchone()[0]\n",
    "\n",
    "        query_suffix = get_query_suffix(row_count)\n",
    "\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS ix_title_vector_cosine ON {text_table_name} USING ivfflat (title_vector vector_cosine_ops) {query_suffix};\n",
    "            CREATE INDEX IF NOT EXISTS ix_content_vector_cosine ON {text_table_name} USING ivfflat (content_vector vector_cosine_ops) {query_suffix};\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"IVFFlat index created for {text_table_name}.\")\n",
    "\n",
    "# Create index for doc_sample table \n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(f'SELECT count(*) FROM {doc_table_name}')\n",
    "        row_count = cursor.fetchone()[0]\n",
    "\n",
    "        query_suffix = get_query_suffix(row_count)\n",
    "\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS ix_chunk_content_vector_cosine ON {doc_table_name} USING ivfflat (chunk_content_vector vector_cosine_ops) {query_suffix};\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"IVFFlat index created for {doc_table_name}.\")\n",
    "\n",
    "# Create index for image_sample table \n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(f'SELECT count(*) FROM {image_table_name}')\n",
    "        row_count = cursor.fetchone()[0]\n",
    "\n",
    "        query_suffix = get_query_suffix(row_count)\n",
    "\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS ix_image_vector_cosine ON {image_table_name} USING ivfflat (image_vector vector_cosine_ops) {query_suffix};\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"IVFFlat index created for {image_table_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
