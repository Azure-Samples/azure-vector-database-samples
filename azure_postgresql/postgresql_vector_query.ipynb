{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search on PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prerequisites\n",
    "  \n",
    "- Generate embeddings - [generate_embeddings.ipynb](../common/generate_embeddings.ipynb)\n",
    "- Create table and ingest embeddings - [postgree_ingestion.ipynb](.../postgree_ingestion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pg_host  = os.getenv(\"POSTGRESQL_HOST\")\n",
    "if pg_host is None or pg_host == \"\":\n",
    "    print(\"POSTGRESQL_HOST environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_user  = os.getenv(\"POSTGRESQL_USERNAME\")\n",
    "if pg_user is None or pg_user == \"\":\n",
    "    print(\"POSTGRESQL_USERNAME environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_password  = os.getenv(\"POSTGRESQL_PASSWORD\")\n",
    "if pg_password is None or pg_password == \"\":\n",
    "    print(\"POSTGRESQL_PASSWORD environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "db_name  = os.getenv(\"POSTGRESQL_DATABASE\")\n",
    "if db_name is None or db_name == \"\":\n",
    "    print(\"POSTGRESQL_DATABASE environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_key  = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "if aoai_key is None or aoai_key == \"\":\n",
    "    print(\"AZURE_OPENAI_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_key  = os.getenv(\"COMPUTER_VISION_KEY\")\n",
    "if com_vision_key is None or com_vision_key == \"\":\n",
    "    print(\"COMPUTER_VISION_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_endpoint = 'https://azure-openai-dnai.openai.azure.com'\n",
    "aoai_api_version = '2023-08-01-preview'\n",
    "aoai_embedding_deployed_model = 'embedding-ada'\n",
    "com_vision_endpoint = 'https://comvis007.cognitiveservices.azure.com/'\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = aoai_key\n",
    "openai.api_base = aoai_endpoint\n",
    "openai.api_version = aoai_api_version\n",
    "\n",
    "postgresql_params = {\n",
    "    \"host\": pg_host,\n",
    "    \"port\": \"5432\", \n",
    "    \"dbname\": db_name,\n",
    "    \"user\": pg_user,\n",
    "    \"password\": pg_password\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query):\n",
    "    vectorize_text_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeText\"  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    } \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "    }  \n",
    "    data = {\n",
    "        'text':query\n",
    "    }\n",
    "\n",
    "    response = requests.post(vectorize_text_url, params=params, headers=headers, json=data)\n",
    "    query_vector = response.json()[\"vector\"]\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "def show_image(image_folder, image):\n",
    "    image_path = os.path.join(image_folder, image)\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple vector search\n",
    "\n",
    "This demo shows how to apply vector search on single columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "query = 'web hosting services'\n",
    "query_vector = get_embedding(query, engine = aoai_embedding_deployed_model)\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "        query_sql = f\"SELECT title FROM text_sample ORDER BY ((content_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "                print(row[0], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata filtering with vector search\n",
    "\n",
    "This demo shows how to apply metadata filtering (SQL - where, order by etc.) on top of vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross column vector search\n",
    "\n",
    "This demo shows how to apply vector search on multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tools for software development'\n",
    "query_vector = get_embedding(query,   engine=aoai_embedding_deployed_model )\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        query_sql = f'''\n",
    "            (\n",
    "                SELECT title, ((title_vector <-> '{query_vector}')) AS content_similarity FROM text_sample\n",
    "                union\n",
    "                SELECT title, ((content_vector <-> '{query_vector}')) AS content_similarity FROM text_sample\n",
    "            ) ORDER BY content_similarity LIMIT 5;\n",
    "        '''\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "                print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid search\n",
    "\n",
    "- This demo shows how to apply vector search in in conjunction with additional search methods, such as lexical search. \n",
    "\n",
    "- Implement a hybrid search that combines semantic keyword search by reranking. Details - https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "query = 'database'\n",
    "\n",
    "def semantic_search(query):\n",
    "    query_vector = get_embedding(query, engine = aoai_embedding_deployed_model)\n",
    "\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            # A higher value of probes provides better recall at the cost of speed.\n",
    "            query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "            cursor.execute(query_sql)\n",
    "\n",
    "            # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "            query_sql = f\"SELECT title FROM text_sample ORDER BY ((content_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "            cursor.execute(query_sql)\n",
    "            return cursor.fetchall()\n",
    "\n",
    "def keyword_search(query):\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT title FROM text_sample, plainto_tsquery('english', %s) query WHERE to_tsvector('english', content) @@ query ORDER BY ts_rank_cd(to_tsvector('english', content), query) DESC LIMIT 5\", (query,))\n",
    "            return cursor.fetchall()\n",
    "\n",
    "def rerank(query, records):\n",
    "    # deduplicate\n",
    "    results = set(itertools.chain(*records))\n",
    "\n",
    "    # re-rank\n",
    "    encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    scores = encoder.predict([(query, item[1]) for item in results])\n",
    "    return [v for _, v in sorted(zip(scores, results), reverse=True)]\n",
    "\n",
    "keyword_search_records = keyword_search(query)\n",
    "semantic_search_records = semantic_search(query)\n",
    "\n",
    "records = list(semantic_search_records) + (list(keyword_search_records))\n",
    "results = rerank(query, records)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document search example\n",
    "\n",
    "- This demo shows how to apply vector search for srarching within documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'web hosting services'\n",
    "query_vector = get_embedding(query, engine = aoai_embedding_deployed_model)\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "        query_sql = f\"SELECT chunk_content FROM doc_sample ORDER BY ((chunk_content_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "                print(row[0], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image search example\n",
    "\n",
    "This demo shows how to apply vector search for searching images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "query = 'flower with hand'\n",
    "image_folder = \"../data/images\"\n",
    "query_vector = vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query)\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "        query_sql = f\"SELECT image FROM image_sample ORDER BY ((image_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for result in records:\n",
    "            show_image(image_folder, result[0])\n",
    "            print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
