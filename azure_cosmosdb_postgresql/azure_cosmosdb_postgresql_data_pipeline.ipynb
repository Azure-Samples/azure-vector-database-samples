{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline - Azure Database for PostgreSQL\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Generate embeddings - [generate_embeddings.ipynb](../common/generate_embeddings.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pg_host  = os.getenv(\"POSTGRESQL_HOST\")\n",
    "if pg_host is None or pg_host == \"\":\n",
    "    print(\"POSTGRESQL_HOST environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_user  = os.getenv(\"POSTGRESQL_USERNAME\")\n",
    "if pg_user is None or pg_user == \"\":\n",
    "    print(\"POSTGRESQL_USERNAME environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_password  = os.getenv(\"POSTGRESQL_PASSWORD\")\n",
    "if pg_password is None or pg_password == \"\":\n",
    "    print(\"POSTGRESQL_PASSWORD environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "db_name  = os.getenv(\"POSTGRESQL_DATABASE\")\n",
    "if db_name is None or db_name == \"\":\n",
    "    print(\"POSTGRESQL_DATABASE environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "postgresql_params = {\n",
    "    \"host\": pg_host,\n",
    "    \"port\": \"5432\", \n",
    "    \"dbname\": db_name,\n",
    "    \"user\": pg_user,\n",
    "    \"password\": pg_password,\n",
    "    \"sslmode\": \"require\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add vector extension\n",
    "\n",
    "The vector extension needs to be enabled in every database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector extension added.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            DO $$\n",
    "            BEGIN\n",
    "            IF NOT EXISTS (\n",
    "                SELECT \n",
    "                FROM   pg_catalog.pg_extension \n",
    "                WHERE  extname = 'vector') THEN\n",
    "\n",
    "                PERFORM CREATE_EXTENSION('vector');\n",
    "            END IF;\n",
    "            END\n",
    "            $$;\n",
    "        \"\"\")\n",
    "        \n",
    "        print('Vector extension added.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table text_sample created.\n",
      "Table doc_sample created.\n",
      "Table image_sample created.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "def create_table(table_name, table_schema):\n",
    "\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(f\"DROP TABLE IF  EXISTS {table_name};\")\n",
    "            cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({table_schema});\")\n",
    "\n",
    "            print(f\"Table {table_name} created.\")\n",
    "\n",
    "## Create text_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    title text,\n",
    "    content text,\n",
    "    category text,\n",
    "    title_vector VECTOR(1536),\n",
    "    content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "create_table(text_table_name, table_schema)\n",
    "\n",
    "## Create doc_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    chunk_content text,\n",
    "    chunk_content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "create_table(doc_table_name, table_schema)\n",
    "\n",
    "## Create image_sample table\n",
    "table_schema = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    image text,\n",
    "    image_vector VECTOR(1024)\n",
    " \"\"\"\n",
    "create_table(image_table_name, table_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest text sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text sample ingested.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import connect\n",
    "\n",
    "text_df = pd.read_json('../data/text/product_docs_embeddings.json')\n",
    "records = text_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {text_table_name}(id, title, content, category, title_vector, content_vector) VALUES(%s, %s, %s, %s, %s, %s);\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Text sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest doc sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc sample ingested.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import connect\n",
    "\n",
    "doc_df = pd.read_json('../data/docs/employee_handbook_embeddings.json')\n",
    "records = doc_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {doc_table_name}(id, chunk_content, chunk_content_vector) VALUES(%s, %s, %s)\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Doc sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest image sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sample ingested.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import connect\n",
    "\n",
    "image_df = pd.read_json('../data/images/images_embeddings.json')\n",
    "records = image_df.values.tolist()\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        insert_sql = f\"INSERT INTO {image_table_name}(id, image, image_vector) VALUES(%s, %s, %s)\"\n",
    "        cursor.executemany(insert_sql, records)\n",
    "\n",
    "        print(\"Image sample ingested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create HNSW Index\n",
    "\n",
    "Details - https://github.com/pgvector/pgvector?tab=readme-ov-file#hnsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW index created for text_sample.\n",
      "HNSW index created for doc_sample.\n",
      "HNSW index created for image_sample.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX ON {text_table_name} USING hnsw (content_vector vector_l2_ops) WITH (m = 16, ef_construction = 64);\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"HNSW index created for {text_table_name}.\")\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX ON {doc_table_name} USING hnsw (chunk_content_vector vector_l2_ops) WITH (m = 16, ef_construction = 64);\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"HNSW index created for {doc_table_name}.\")\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        index_query = f\"\"\"\n",
    "            CREATE INDEX ON {image_table_name} USING hnsw (image_vector vector_l2_ops) WITH (m = 16, ef_construction = 64);\n",
    "        \"\"\"\n",
    "        cursor.execute(index_query)\n",
    "\n",
    "        print(f\"HNSW index created for {image_table_name}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
