{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search on PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prerequisites\n",
    "  \n",
    "- Generate embeddings - [generate_embeddings.ipynb](../common/generate_embeddings.ipynb)\n",
    "- Create table and ingest embeddings - [postgree_ingestion.ipynb](.../postgree_ingestion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import (\n",
    "    IndexingSchedule,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SemanticConfiguration,\n",
    "    SimpleField,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "import openai\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "cosmos_db_api_endpoint  = os.getenv(\"cosmos_db_api_endpoint\")\n",
    "if cosmos_db_api_endpoint is None or cosmos_db_api_endpoint == \"\":\n",
    "    print(\"cosmos_db_api_endpoint environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "cosmos_db_api_key  = os.getenv(\"cosmos_db_api_key\")\n",
    "if cosmos_db_api_key is None or cosmos_db_api_key == \"\":\n",
    "    print(\"cosmos_db_api_key environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "cog_search_endpoint  = os.getenv(\"cog_search_endpoint\")\n",
    "if cog_search_endpoint is None or cog_search_endpoint == \"\":\n",
    "    print(\"cog_search_endpoint environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "cog_search_key  = os.getenv(\"cog_search_key\")\n",
    "if cog_search_key is None or cog_search_key == \"\":\n",
    "    print(\"cog_search_key environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_embedding_deployed_model  = os.getenv(\"aoai_embedding_deployed_model\")\n",
    "if aoai_embedding_deployed_model is None or aoai_embedding_deployed_model == \"\":\n",
    "    print(\"aoai_embedding_deployed_model environment variable not set.\")\n",
    "    exit()   \n",
    "\n",
    "\n",
    "aoai_key  = os.getenv(\"aoai_key\")\n",
    "if aoai_key is None or aoai_key == \"\":\n",
    "    print(\"aoai_key environment variable not set.\")\n",
    "    exit()   \n",
    "\n",
    "\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query):\n",
    "    vectorize_text_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeText\"  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    } \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "    }  \n",
    "    data = {\n",
    "        'text':query\n",
    "    }\n",
    "\n",
    "    response = requests.post(vectorize_text_url, params=params, headers=headers, json=data)\n",
    "    query_vector = response.json()[\"vector\"]\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "def show_image(image_folder, image):\n",
    "    image_path = os.path.join(image_folder, image)\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##secrets\n",
    "##todo\n",
    "\n",
    "##https://learn.microsoft.com/en-us/training/modules/search-azure-cosmos-db-sql-api-data-azure-cognitive-search/\n",
    "\n",
    "##https://learn.microsoft.com/en-us/azure/search/search-howto-index-cosmosdb\n",
    "\n",
    "##https://github.com/microsoft/AzureDataRetrievalAugmentedGenerationSamples/blob/main/Python/AzureSQL_CognitiveSearch/AzureSQL_CogSearch.ipynb\n",
    "##https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-python-create-container  \n",
    "aoai_endpoint = \"https://openaitesteise.openai.azure.com/\"\n",
    "\n",
    "##https://learn.microsoft.com/en-gb/azure/search/search-create-service-portal\n",
    "cog_search_endpoint  = \"https://cosmossearch.search.windows.net\"\n",
    "cog_search_key  = \"VYHMZj5OotW3UQ3CXYsM0vOFmmh6wCHbokIIEoXze4AzSeANr6lK\"\n",
    "\n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_base = aoai_endpoint\n",
    "openai.api_version = \"2023-05-15\" ##\"2023-06-01-preview\"\n",
    "aoai_api_version= \"2023-06-01-preview\"\n",
    "aoai_embedding_deployed_model = \"text-embedding-ada-002\"\n",
    "aoai_key = \"b3319bcf227a428aa5df532e84716f7e\"\n",
    "\n",
    "\n",
    "openai_completions_deployment = \"gpt-35-turbo\" ##completions_deployment , embeddings_deployment \n",
    "\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "##connection params\n",
    "cosmos_db_api_endpoint= \"https://lilem.documents.azure.com:443/\"\n",
    "cosmos_db_api_key= \"TqDjr7pe4Xo64MeZfIItqKjgeFByOduzFFTwJSVGsSqLnB0ZTTxagQ6qOH9mpmwJEEeFy5nVOz7RACDbMpyXww==\"   \n",
    "\n",
    "client = CosmosClient(cosmos_db_api_endpoint, credential=cosmos_db_api_key)\n",
    "\n",
    "\n",
    "#cosmosdb_database_name = \"Vector_DB\"\n",
    "#cosmosdb_container_name = \"text_sample\"\n",
    "\n",
    "database_name = \"Vector_DB\"\n",
    "container_name = 'text_sample'\n",
    "\n",
    "\n",
    "\n",
    "# Configure Azure Cognitive Search\n",
    "cog_search_endpoint  = \"https://cosmossearch.search.windows.net\"\n",
    "cog_search_key  = \"VYHMZj5OotW3UQ3CXYsM0vOFmmh6wCHbokIIEoXze4AzSeANr6lK\"\n",
    "index_name = \"https://cognitivepoc.search.windows.net\"\n",
    "\n",
    "container_name = 'text_sample'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "##from azure.search.documents.indexes import SimpleField, SearchableField, Index\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Cosmos DB client\n",
    "cosmos_client = CosmosClient(cosmos_db_api_endpoint, cosmos_db_api_key)\n",
    "database = cosmos_client.get_database_client(database_name)\n",
    "container = database.get_container_client(container_name)\n",
    "\n",
    "# Initialize Azure Cognitive Search client\n",
    "#search_client = SearchClient(account_name=cog_search_endpoint, index_name=index_name, index_version=\"2020-06-30\", credential=cog_search_key)\n",
    "search_client = SearchClient(endpoint=cog_search_endpoint, index_name=index_name, credential=cog_search_key)\n",
    "\n",
    "#index = SearchIndex(\n",
    "#    name=index_name,\n",
    "#    fields=[\n",
    "##        SimpleField(name=\"title\", type=\"Edm.String\", key=True, searchable=True),\n",
    "#        SearchableField(name=\"content_vector\", type=\"Collection(Edm.Double)\")\n",
    " #   ]\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "# Define the fields for the index\n",
    "fields = [\n",
    "    SimpleField(name=\"title\", type=\"Edm.String\", key=True, searchable=True),\n",
    "    SearchableField(name=\"content_vector\", type=\"Collection(Edm.Double)\")\n",
    "]\n",
    "\n",
    "# Create or update the search index with the defined fields\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "#search_client.create_index(index)\n",
    "\n",
    "#  Query Cosmos DB using Azure Cognitive Search\n",
    "query = 'web hosting services'\n",
    "\n",
    "# Query Azure Cognitive Search\n",
    "results = search_client.search(search_text=query, include_total_count=True, top=5)\n",
    "\n",
    "# Display results\n",
    "#for result in results:\n",
    " #   print(result['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x1c9f6b68410 state=finished raised AuthenticationError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\embeddings_utils.py:23\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, engine, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:151\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[0;32m    143\u001b[0m         timeout,\n\u001b[0;32m    144\u001b[0m         stream,\n\u001b[0;32m    145\u001b[0m         headers,\n\u001b[0;32m    146\u001b[0m         request_timeout,\n\u001b[0;32m    147\u001b[0m         typed_api_type,\n\u001b[0;32m    148\u001b[0m         requestor,\n\u001b[0;32m    149\u001b[0m         url,\n\u001b[0;32m    150\u001b[0m         params,\n\u001b[1;32m--> 151\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__prepare_create_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:108\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    106\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 108\u001b[0m requestor \u001b[38;5;241m=\u001b[39m \u001b[43mapi_requestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIRequestor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:139\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_base \u001b[38;5;241m=\u001b[39m api_base \u001b[38;5;129;01mor\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mapi_base\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    141\u001b[0m     ApiType\u001b[38;5;241m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ApiType\u001b[38;5;241m.\u001b[39mfrom_str(openai\u001b[38;5;241m.\u001b[39mapi_type)\n\u001b[0;32m    144\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo API key provided. You can set your API key in code using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key = <API-KEY>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai.api_key_path = <PATH>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SearchClient, SearchIndexingBufferedSender  \n\u001b[0;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtools for software development\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maoai_embedding_deployed_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m search_client \u001b[38;5;241m=\u001b[39m SearchClient(cog_search_endpoint,  AzureKeyCredential(aoai_key))\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n\u001b[0;32m    329\u001b[0m     sleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(retry_state)\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x1c9f6b68410 state=finished raised AuthenticationError>]"
     ]
    }
   ],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender  \n",
    "\n",
    "query = 'tools for software development'\n",
    "query_vector = get_embedding(query, k=3,  engine=aoai_embedding_deployed_model )\n",
    "search_client = SearchClient(cog_search_endpoint,  AzureKeyCredential(aoai_key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tools for software development'\n",
    "query_vector = get_embedding(query,   engine=aoai_embedding_deployed_model )\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        query_sql = f'''\n",
    "            (\n",
    "                SELECT title, ((title_vector <-> '{query_vector}')) AS content_similarity FROM text_sample\n",
    "                union\n",
    "                SELECT title, ((content_vector <-> '{query_vector}')) AS content_similarity FROM text_sample\n",
    "            ) ORDER BY content_similarity LIMIT 5;\n",
    "        '''\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "                print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid search\n",
    "\n",
    "- This demo shows how to apply vector search in in conjunction with additional search methods, such as lexical search. \n",
    "\n",
    "- Implement a hybrid search that combines semantic keyword search by reranking. Details - https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "query = 'database'\n",
    "\n",
    "def semantic_search(query):\n",
    "    query_vector = get_embedding(query, engine = aoai_embedding_deployed_model)\n",
    "\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            # A higher value of probes provides better recall at the cost of speed.\n",
    "            query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "            cursor.execute(query_sql)\n",
    "\n",
    "            # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "            query_sql = f\"SELECT title FROM text_sample ORDER BY ((content_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "            cursor.execute(query_sql)\n",
    "            return cursor.fetchall()\n",
    "\n",
    "def keyword_search(query):\n",
    "    with connect(**postgresql_params) as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT title FROM text_sample, plainto_tsquery('english', %s) query WHERE to_tsvector('english', content) @@ query ORDER BY ts_rank_cd(to_tsvector('english', content), query) DESC LIMIT 5\", (query,))\n",
    "            return cursor.fetchall()\n",
    "\n",
    "def rerank(query, records):\n",
    "    # deduplicate\n",
    "    results = set(itertools.chain(*records))\n",
    "\n",
    "    # re-rank\n",
    "    encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    scores = encoder.predict([(query, item[1]) for item in results])\n",
    "    return [v for _, v in sorted(zip(scores, results), reverse=True)]\n",
    "\n",
    "keyword_search_records = keyword_search(query)\n",
    "semantic_search_records = semantic_search(query)\n",
    "\n",
    "records = list(semantic_search_records) + (list(keyword_search_records))\n",
    "results = rerank(query, records)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document search example\n",
    "\n",
    "This demo shows how to apply vector search for srarching within documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'web hosting services'\n",
    "query_vector = get_embedding(query, engine = aoai_embedding_deployed_model)\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "        query_sql = f\"SELECT chunk_content FROM doc_sample ORDER BY ((chunk_content_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for row in records:\n",
    "                print(row[0], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image search example\n",
    "\n",
    "This demo shows how to apply vector search for searching images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "\n",
    "query = 'flower with hand'\n",
    "image_folder = \"../data/images\"\n",
    "query_vector = vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query)\n",
    "\n",
    "with connect(**postgresql_params) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # A higher value of probes provides better recall at the cost of speed.\n",
    "        query_sql = f\"SET ivfflat.probes = 10;\"\n",
    "        cursor.execute(query_sql)\n",
    "\n",
    "        # Postgres supports L2 distance (<->), inner product (<#>) and cosine distance (<=>)\n",
    "        query_sql = f\"SELECT image FROM image_sample ORDER BY ((image_vector <=> '{query_vector}')) LIMIT 5;\"\n",
    "        cursor.execute(query_sql)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "        for result in records:\n",
    "            show_image(image_folder, result[0])\n",
    "            print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
