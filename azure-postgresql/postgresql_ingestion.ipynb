{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion to PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pg_host  = os.getenv(\"POSTGRESQL_HOST\")\n",
    "if pg_host is None or pg_host == \"\":\n",
    "    print(\"POSTGRESQL_HOST environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_user  = os.getenv(\"POSTGRESQL_USERNAME\")\n",
    "if pg_user is None or pg_user == \"\":\n",
    "    print(\"POSTGRESQL_USERNAME environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "pg_password  = os.getenv(\"POSTGRESQL_PASSWORD\")\n",
    "if pg_password is None or pg_password == \"\":\n",
    "    print(\"POSTGRESQL_PASSWORD environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "db_name  = os.getenv(\"POSTGRESQL_DATABASE\")\n",
    "if db_name is None or db_name == \"\":\n",
    "    print(\"POSTGRESQL_DATABASE environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "postgresql_params = {\n",
    "    \"host\": pg_host,\n",
    "    \"port\": \"5432\", \n",
    "    \"dbname\": db_name,\n",
    "    \"user\": pg_user,\n",
    "    \"password\": pg_password\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 \n",
    "\n",
    "connection = psycopg2.connect(**postgresql_params)\n",
    "print(\"Connection established.\")\n",
    "\n",
    "\n",
    "\n",
    "## Create text_sample table\n",
    "table_schema_data = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    title text,\n",
    "    content text,\n",
    "    category text,\n",
    "    title_vector VECTOR(1536),\n",
    "    content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector\"); \n",
    "\n",
    "connection.commit()\n",
    "print(\"Adding extension\")\n",
    "\n",
    "\n",
    "cursor.execute(f\"DROP TABLE IF  EXISTS {text_table_name} \")\n",
    "cursor.execute(f\"CREATE TABLE IF NOT EXISTS {text_table_name} ({table_schema_data});\")\n",
    "connection.commit()\n",
    "print(\"Table text_sample created.\")\n",
    "cursor.close()\n",
    "\n",
    "## Create doc_sample table\n",
    "table_schema_data = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    chunk_content text,\n",
    "    chunk_content_vector VECTOR(1536)\n",
    " \"\"\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF  EXISTS {doc_table_name} \")\n",
    "cursor.execute(f\"CREATE TABLE IF NOT EXISTS {doc_table_name} ({table_schema_data});\")\n",
    "connection.commit()\n",
    "print(\"Table text_sample created.\")\n",
    "cursor.close()\n",
    "\n",
    "## Create doc_sample table\n",
    "table_schema_data = \"\"\"\n",
    "    id smallint PRIMARY KEY,\n",
    "    image text,\n",
    "    image_vector VECTOR(1024)\n",
    " \"\"\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF  EXISTS {image_table_name} \")\n",
    "cursor.execute(f\"CREATE TABLE IF NOT EXISTS {image_table_name} ({table_schema_data});\")\n",
    "connection.commit()\n",
    "print(\"Table text_sample created.\")\n",
    "cursor.close()\n",
    "\n",
    "connection.close()\n",
    "print(\"close connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest text sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_df = pd.read_json('../data/text/product_docs_embeddings.json')\n",
    "\n",
    "connection = psycopg2.connect(**postgresql_params)\n",
    "print(\"Connection established.\")\n",
    "\n",
    "insert_sql = f\"INSERT INTO {text_table_name}(id, title, content, category, title_vector, content_vector) VALUES(%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "records = text_df.values.tolist()\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(insert_sql, records)\n",
    "\n",
    "connection.commit()\n",
    "print(\"Text sample ingested.\")\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest doc sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_df = pd.read_json('../data/docs/employee_handbook_embeddings.json')\n",
    "\n",
    "connection = psycopg2.connect(**postgresql_params)\n",
    "print(\"Connection established.\")\n",
    "\n",
    "insert_sql = f\"INSERT INTO {doc_table_name}(id, chunk_content, chunk_content_vector) VALUES(%s, %s, %s)\"\n",
    "\n",
    "records = doc_df.values.tolist()\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(insert_sql, records)\n",
    "\n",
    "connection.commit()\n",
    "print(\"Doc sample ingested.\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest image sample with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "image_df = pd.read_json('../data/images/images_embeddings.json')\n",
    "\n",
    "connection = psycopg2.connect(**postgresql_params)\n",
    "print(\"Connection established.\")\n",
    "\n",
    "insert_sql = f\"INSERT INTO {image_table_name}(id, image, image_vector) VALUES(%s, %s, %s)\"\n",
    "\n",
    "records = image_df.values.tolist()\n",
    "cursor = connection.cursor()\n",
    "cursor.executemany(insert_sql, records)\n",
    "\n",
    "connection.commit()\n",
    "print(\"Image sample ingested.\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the psycopg2 library if you're using PostgreSQL\n",
    "import psycopg2\n",
    "import math\n",
    "\n",
    "connection = psycopg2.connect(**postgresql_params)\n",
    "cursor = connection.cursor()\n",
    "print(\"Connection established.\")\n",
    "\n",
    "\n",
    "##Checking if the table has more than 1000 of rows so it can be divided in lists while using ivfflat\n",
    "##https://github.com/pgvector/pgvector#ivfflat\n",
    "\n",
    "# Count the number of rows \n",
    "cursor.execute(f'SELECT count(*) FROM {text_table_name}')\n",
    "rows = cursor.fetchone()[0]\n",
    "\n",
    "\n",
    "if rows >= 1000:\n",
    "    # Determine the number of lists based on the number of rows\n",
    "    if rows <= 1000000:\n",
    "        lists = rows / 1000\n",
    "    else:\n",
    "        lists = math.sqrt(rows)\n",
    "\n",
    "    index_schema_text = f\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS ix_title_vector_cosine\n",
    "        ON {text_table_name}\n",
    "        USING ivfflat (title_vector vector_cosine_ops)\n",
    "        WITH (lists = {int(lists)});\n",
    "\n",
    "        CREATE INDEX IF NOT EXISTS ix_content_vector_cosine\n",
    "        ON {text_table_name}\n",
    "        USING ivfflat (content_vector vector_cosine_ops)\n",
    "        WITH (lists = {int(lists)});\n",
    "\n",
    "    \"\"\"\n",
    "else:\n",
    "\n",
    "    # For the text_sample table\n",
    "    index_schema_text = f\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS ix_title_vector_cosine ON {text_table_name} USING ivfflat  (title_vector vector_cosine_ops);\n",
    "        CREATE INDEX IF NOT EXISTS ix_content_vector_cosine ON {text_table_name} USING ivfflat  (content_vector vector_cosine_ops);\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Count the number of rows \n",
    "cursor.execute(f'SELECT count(*) FROM {doc_table_name}')\n",
    "rows = cursor.fetchone()[0]\n",
    "\n",
    "if rows >= 1000:\n",
    "    # Determine the number of lists based on the number of rows\n",
    "    if rows <= 1000000:\n",
    "        lists = rows / 1000\n",
    "    else:\n",
    "        lists = math.sqrt(rows)\n",
    "\n",
    "    index_schema_text = f\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS ix_chunk_content_vector_cosine\n",
    "        ON {doc_table_name}\n",
    "        USING ivfflat (chunk_content_vector vector_cosine_ops)\n",
    "        WITH (lists = {int(lists)});\n",
    "    \"\"\"\n",
    "else:\n",
    "    # For the doc_sample table\n",
    "    index_schema_doc = f\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS ix_chunk_content_vector_cosine ON {doc_table_name} USING ivfflat  (chunk_content_vector vector_cosine_ops);\n",
    "    \"\"\"\n",
    "\n",
    "##FTS on text_Sample\n",
    "index_schema_FTS = \"CREATE INDEX IF NOT EXISTS idx_text_sample_content_gin ON text_sample USING GIN (to_tsvector('english', content))\"\n",
    "\n",
    "\n",
    "# Create HSNW indexes for the text_sample table\n",
    "cursor.execute(index_schema_text)\n",
    "print('Index ivfflat text_sample ')\n",
    "\n",
    "# Create HSNW indexes for the doc_sample table\n",
    "cursor.execute(index_schema_doc)\n",
    "print('Index ivfflat doc_sample ')\n",
    "\n",
    "# Perform Full-Text Search (Keyword Search) using PostgreSQL's FTS\n",
    "cursor.execute(index_schema_FTS)\n",
    "print('Index FTS text_sample ')\n",
    "\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "print(\"close connection.\")\n",
    "\n",
    "## hnsw is failing with the postgres 13 or 15 version with the vector extension enable. \n",
    "##UndefinedObject: access method \"hnsw\" does not exist\n",
    "##The other option of index -  ivfflat  works but it seems it would not be suitable unless we have more data according tas per reference: \n",
    "# \"a good place to start is rows / 1000 for up to 1M rows and sqrt(rows) for over 1M rows\" (ref https://github.com/pgvector/pgvector) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
