{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search via Python SDK\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "## Prerequisites\n",
    "To run the code, set up the conda environment using the environment.yml."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: openai[datalib] in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (3.8.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (2.1.1)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (2.0.3.230814)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai[datalib]) (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl>=3.0.7->openai[datalib]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2.3->openai[datalib]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.3->openai[datalib]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.3->openai[datalib]) (2023.3)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas-stubs>=1.1.0.11->openai[datalib]) (2023.3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai[datalib]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai[datalib]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai[datalib]) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai[datalib]) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai[datalib]) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai[datalib]) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.3->openai[datalib]) (1.16.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: azure-ai-textanalytics in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-textanalytics) (1.29.4)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-textanalytics) (1.1.28)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-textanalytics) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-textanalytics) (4.7.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2023.7.22)\n",
      "Requirement already satisfied: azure-search-documents in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.4.0a20230509004)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents) (1.29.4)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents) (2023.7.22)\n",
      "Requirement already satisfied: azure-search in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0b2)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.2.2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search) (1.29.4)\n",
      "Requirement already satisfied: msrest>=0.6.10 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search) (0.7.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.2.2->azure-search) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.2.2->azure-search) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.2.2->azure-search) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msrest>=0.6.10->azure-search) (2023.7.22)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msrest>=0.6.10->azure-search) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msrest>=0.6.10->azure-search) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.2.2->azure-search) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.2.2->azure-search) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.2.2->azure-search) (2.0.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-search) (3.2.2)\n",
      "Requirement already satisfied: azure-core in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.29.4)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core) (2023.7.22)\n",
      "Requirement already satisfied: azure-storage-blob in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (12.18.2)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob) (1.29.4)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob) (41.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob) (4.7.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement azure-search-documents==11.4.0 (from versions: 1.0.0b2, 1.0.0b3, 1.0.0b4, 11.0.0, 11.1.0b1, 11.1.0b2, 11.1.0b3, 11.1.0b4, 11.1.0, 11.2.0b1, 11.2.0b2, 11.2.0b3, 11.2.0, 11.2.1, 11.2.2, 11.3.0b1, 11.3.0b2, 11.3.0b3, 11.3.0b4, 11.3.0b5, 11.3.0b6, 11.3.0b7, 11.3.0b8, 11.3.0, 11.4.0b1, 11.4.0b2, 11.4.0b3, 11.4.0b4, 11.4.0b5, 11.4.0b6, 11.4.0b7, 11.4.0b8, 11.4.0b9)\n",
      "ERROR: No matching distribution found for azure-search-documents==11.4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-identity in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity) (1.29.4)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity) (41.0.4)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity) (1.24.1)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (4.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity) (306)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (2023.7.22)\n",
      "Looking in indexes: https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/\n",
      "Requirement already satisfied: azure-search-documents==11.4.0a20230509004 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.4.0a20230509004)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents==11.4.0a20230509004) (1.29.4)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents==11.4.0a20230509004) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-search-documents==11.4.0a20230509004) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lilem\\appdata\\roaming\\python\\python311\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilem\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0a20230509004) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install openai[datalib]\n",
    "!pip install python-dotenv\n",
    "!pip install azure-ai-textanalytics\n",
    "!pip install azure-search-documents --pre\n",
    "!pip install azure-search --pre --upgrade\n",
    "!pip install azure-core --pre --upgrade\n",
    "!pip install azure-storage-blob\n",
    "#!pip install azure-search-documents==11.4.0\n",
    "!pip install azure-identity\n",
    "!pip install azure-search-documents==11.4.0a20230509004 -i https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "\n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\") \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ComplexField,\n",
    "    CorsOptions,\n",
    "    SearchIndex,\n",
    "    ScoringProfile,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField\n",
    ")\n",
    "##https://azuresdkdocs.blob.core.windows.net/$web/python/azure-search-documents/latest/index.html\n",
    "def get_index_client() -> SearchIndexClient:\n",
    "    return SearchIndexClient(service_endpoint, AzureKeyCredential(key))\n",
    "\n",
    "def create_index(index_name, fields, vector_search, semantic_title_field_name, semantic_content_field_names):\n",
    "    semantic_settings = SemanticSettings(\n",
    "        configurations=[SemanticConfiguration(\n",
    "            name='default',\n",
    "            prioritized_fields=PrioritizedFields(\n",
    "                title_field=SemanticField(field_name=semantic_title_field_name), prioritized_content_fields=[SemanticField(field_name=field_name) for field_name in semantic_content_field_names]))])\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "        semantic_settings=semantic_settings)\n",
    "    index_client = get_index_client()\n",
    "    return index_client.create_index(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_content</th>\n",
       "      <th>chunk_content_vector</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contoso Electronics \\nEmployee Handbook  \\n \\n...</td>\n",
       "      <td>[-0.0134241888, 0.0083369836, 0.00018061460000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edge systems that are both reliable and effici...</td>\n",
       "      <td>[-0.0078642182, 0.0030302808, -0.0163918491, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edge systems that are both reliable and effici...</td>\n",
       "      <td>[-0.0107993353, 0.0036727316, -0.009540895, -0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>customers.  \\n \\nCompany Values:  \\n1. Quality...</td>\n",
       "      <td>[-0.018283184600000002, -0.0022870835000000003...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we work and live.  \\nPerformance Reviews  \\n \\...</td>\n",
       "      <td>[-0.016625782500000002, -6.20042e-05, 0.031033...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       chunk_content  \\\n",
       "0  Contoso Electronics \\nEmployee Handbook  \\n \\n...   \n",
       "1  edge systems that are both reliable and effici...   \n",
       "2  edge systems that are both reliable and effici...   \n",
       "3  customers.  \\n \\nCompany Values:  \\n1. Quality...   \n",
       "4  we work and live.  \\nPerformance Reviews  \\n \\...   \n",
       "\n",
       "                                chunk_content_vector  id  \n",
       "0  [-0.0134241888, 0.0083369836, 0.00018061460000...   0  \n",
       "1  [-0.0078642182, 0.0030302808, -0.0163918491, -...   1  \n",
       "2  [-0.0107993353, 0.0036727316, -0.009540895, -0...   2  \n",
       "3  [-0.018283184600000002, -0.0022870835000000003...   3  \n",
       "4  [-0.016625782500000002, -6.20042e-05, 0.031033...   4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('../data/pdf/employee_handbook_chunk_embeddings.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PostGres Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n",
      "Numeric PostgreSQL Version: 15.3\n",
      "Greater than 15 configuration, table column use Array\n",
      "Drop the old table and Create a new(if old existed)\n",
      "Connection Closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import re\n",
    "\n",
    "\n",
    "# Update connection string information\n",
    "postgree_params = {\n",
    "    \"host\": \"pvector.postgres.database.azure.com\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"administrators\",\n",
    "    \"password\": \"Contoso!0000\"\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**postgree_params)\n",
    "print(\"Connection established\")\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# SQL query to fetch PostgreSQL version\n",
    "query = \"SELECT version();\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch the result\n",
    "version_string = cursor.fetchone()[0]\n",
    "\n",
    "\n",
    "# Use regular expression to extract the PostgreSQL version\n",
    "numeric_version_match = re.search(r'PostgreSQL (\\d+\\.\\d+)', version_string)\n",
    "if numeric_version_match:\n",
    "    Sversion = numeric_version_match.group(1)\n",
    "else:\n",
    "    Sversion = \"Version not found\"\n",
    "\n",
    "# Print the extracted PostgreSQL version\n",
    "print(f\"Numeric PostgreSQL Version: {Sversion}\")\n",
    "\n",
    "\n",
    "# Remove the period and convert to float\n",
    "version = float(Sversion.replace(\".\", \"\"))\n",
    "\n",
    "if version > 14:\n",
    "    print(\"Greater than 15 configuration, table column use Array\")\n",
    "    ##Postgree version<14 has no extension vector\n",
    "    table_schema_data = \"\"\"\n",
    "      id_serial UUID DEFAULT gen_random_uuid() PRIMARY KEY,\n",
    "      chunk_content  text,\n",
    "      chunk_content_vector  double precision[]\n",
    "\"\"\"\n",
    "if version <= 14:\n",
    "      print(\"Smaller than 15 configuration, table column use Vector\")\n",
    "      #install pgvector -> need to add the extension at the database before create.\n",
    "      ##Postgree version<14\n",
    "      cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector\"); \n",
    "      conn.commit()\n",
    "      print(\"Adding extension - vector\")\n",
    "\n",
    "      # Define the table schema if needed\n",
    "      table_schema_data = \"\"\"\n",
    "            id_serial UUID DEFAULT gen_random_uuid() PRIMARY KEY,\n",
    "            chunk_content text,\n",
    "            chunk_content_vector VECTOR(1536)\n",
    "      \"\"\"\n",
    "\n",
    "\n",
    "# Drop previous table of same name if one exists\n",
    "# Replace 'your_table_name' with the name of your PostgreSQL table\n",
    "table_name = \"chunk_content_embeddings\"\n",
    "table_schema = \"chunk\"\n",
    "\n",
    "cursor.execute(f\"CREATE schema IF NOT EXISTS {table_schema}\"); ##postgis\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Drop table\n",
    "cursor.execute(f\"DROP TABLE IF  EXISTS {table_schema}.{table_name} \")\n",
    "#Table Creatin\n",
    "cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_schema}.{table_name} ({table_schema_data});\")\n",
    "print(\"Drop the old table and Create a new(if old existed)\")\n",
    "\n",
    "\n",
    "\n",
    "# Clean up\n",
    "# Close the cursor and connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Connection Closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n",
      "Connection Closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Update connection string information\n",
    "\n",
    "postgree_params = {\n",
    "    \"host\": \"pvector.postgres.database.azure.com\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"administrators\",\n",
    "    \"password\": \"Contoso!0000\"\n",
    "}\n",
    "\n",
    "\n",
    "table_name = \"chunk_content_embeddings\"\n",
    "table_schema = \"chunk\"\n",
    "\n",
    "#host = \"server.postgres.database.azure.com\"\n",
    "#dbname = \"dataabse\"\n",
    "#user = \"user name\"\n",
    "#password = \" password\"\n",
    "#port = \"port - postgree usually use 5432\"\n",
    "#sslmode = \"require\"\n",
    "\n",
    "\n",
    "# Assuming you have already defined your df DataFrame and postgree_params\n",
    "conn = psycopg2.connect(**postgree_params)\n",
    "print(\"Connection established\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "total_records = df.shape[0]\n",
    "\n",
    "# Iterate through your DataFrame and insert embeddings into PostgreSQL\n",
    "for index, row in df.iterrows():\n",
    "    insert_sql = f'''\n",
    "       INSERT INTO {table_schema}.{table_name} (chunk_content, chunk_content_vector)\n",
    "        VALUES (%s, ARRAY[%s]::double precision[]);\n",
    "    '''\n",
    "    # Use parameterized queries to safely insert data\n",
    "    cursor.execute(insert_sql, (row['chunk_content'], row['chunk_content_vector']))\n",
    "\n",
    "\n",
    "# Commit the changes and close the cursor and connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Connection Closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Query Vector using Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n",
      "Query table\n",
      "Similar Pair - Euclidean Distance: 0.23853913387441963\n",
      "Similar Pair - Euclidean Distance: 0.48445206589993106\n",
      "Similar Pair - Euclidean Distance: 0.4735859061045146\n",
      "Similar Pair - Euclidean Distance: 0.42803151232637265\n",
      "Similar Pair - Euclidean Distance: 0.40827244979223315\n",
      "Similar Pair - Euclidean Distance: 0.4730061688620234\n",
      "Similar Pair - Euclidean Distance: 0.42493653521070196\n",
      "Similar Pair - Euclidean Distance: 0.45966613627218855\n",
      "Connection Closed\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np  # for vector operations\n",
    "import psycopg2  \n",
    "\n",
    "# Update connection string information\n",
    "\n",
    "postgree_params = {\n",
    "    \"host\": \"server.postgres.database.azure.com\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"user name\",\n",
    "    \"password\": \" password\"\n",
    "}\n",
    "\n",
    "\n",
    "table_name = \"chunk_content_embeddings\"\n",
    "table_schema = \"chunk\"\n",
    "\n",
    "# Define a threshold for similarity (adjust as needed)\n",
    "threshold = 0.5  \n",
    "\n",
    "# Create a list to store similar vector pairs\n",
    "similar_pairs = []\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(**postgree_params)\n",
    "print(\"Connection established\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "##Calculate the euclidean distance under the same column\n",
    "##using limit (like top) to filter the sample\n",
    "\n",
    "query = f'''\n",
    "    SELECT t1.chunk_content_vector as chunk_content_vector_1,\n",
    "           t2.chunk_content_vector as chunk_content_vector_2,\n",
    "           t1.chunk_content as chunk_content_t1,\n",
    "           t2.chunk_content as chunk_content_t2\n",
    "    FROM {table_schema}.{table_name} t1\n",
    "    CROSS JOIN\n",
    "        {table_schema}.{table_name} t2\n",
    "WHERE\n",
    "    t1.chunk_content_vector < t2.chunk_content_vector\n",
    "    LIMIT 100;\n",
    "'''\n",
    "print(\"Query table\")\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch and process the results\n",
    "query = cursor.fetchall()\n",
    "#for row in query:\n",
    "#    print(f\"chunk_content: {row[0]}, chunk_content_vector: {row[1]}\")\n",
    "\n",
    "\n",
    "# Function to calculate Euclidean distance between two vectors\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.linalg.norm(np.array(vector1) - np.array(vector2))\n",
    "\n",
    "# Iterate through the results and calculate the Euclidean distance\n",
    "for row in query:\n",
    "    vector1 = row[0]\n",
    "    vector2 = row[1]\n",
    "    \n",
    "    distance = euclidean_distance(vector1, vector2)\n",
    "    #print(f\"Euclidean Distance: {distance}\")\n",
    "\n",
    "    # Check if the distance is below the threshold\n",
    "    if distance < threshold:\n",
    "        similar_pairs.append((vector1, vector2, distance, ))\n",
    "\n",
    "# Print or process the similar pairs\n",
    "for pair in similar_pairs:\n",
    "    vector1, vector2, distance = pair\n",
    "    print(f\"Similar Pair - Euclidean Distance: {distance}\")\n",
    "\n",
    "    \n",
    "# Close the database connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Connection Closed\")\n",
    "\n",
    "# Iterate through the results and calculate the Euclidean distance\n",
    "#for row in query:\n",
    "#    vector1 = row[0]\n",
    "#    vector2 = row[1]\n",
    "    #vector3 = row[2]\n",
    "    #vector4 = row[3]\n",
    " #   distance = euclidean_distance(vector1, vector2)\n",
    "    #print(f\"Euclidean Distance: {distance}\")\n",
    "\n",
    "    # Check if the distance is below the threshold\n",
    "  #  if distance < threshold:\n",
    "        #similar_pairs.append((vector1, vector2, distance,vector3, vector4 ))\n",
    "   #     similar_pairs.append((vector1, vector2, distance))\n",
    "\n",
    "# Print or process the similar pairs\n",
    "#for pair in similar_pairs:\n",
    " #   vector1, vector2,vector3, vector4, distance = pair\n",
    "  #  print(f\"Similar Pair - Euclidean Distance: {distance} \\n\\n\")\n",
    "    #print(f\"Values are 1: {vector3} \\n\\n\")\n",
    "    #print(f\"Values are 2:  {vector4}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Vector Search with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git\\Azure Vector Search Repo\\azure-vector-search-samples\\azure-postgresql\\postgresql_doc.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtools for software development\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Extract the embedding vector\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m embedding \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mquery, engine\u001b[39m=\u001b[39;49mAZURE_OPENAI_EMBEDDING_DEPLOYMENT, deployment \u001b[39m=\u001b[39;49mAZURE_OPENAI_EMBEDDING_DEPLOYMENT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m query_vector \u001b[39m=\u001b[39m embedding[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Calculate the query vector\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Azure%20Vector%20Search%20Repo/azure-vector-search-samples/azure-postgresql/postgresql_doc.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#query_vector=get_embedding(query, engine = AZURE_OPENAI_EMBEDDING_DEPLOYMENT)##\"text-embedding-ada-002\" \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lilem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from azure.search.documents.models import Vector  \n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import openai\n",
    "\n",
    "\n",
    "# Update connection string information\n",
    "\n",
    "postgree_params = {\n",
    "    \"host\": \"server.postgres.database.azure.com\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"user name\",\n",
    "    \"password\": \" password\"\n",
    "}\n",
    "\n",
    "#host = \"server.postgres.database.azure.com\"\n",
    "#dbname = \"dataabse\"\n",
    "#user = \"user name\"\n",
    "#password = \" password\"\n",
    "#port = \"port - postgree usually use 5432\"\n",
    "#sslmode = \"require\"\n",
    "\n",
    "conn = psycopg2.connect(**postgree_params)\n",
    "print(\"Connection established\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the query\n",
    "\n",
    "table_name = \"chunk_content_embeddings\"\n",
    "table_schema = \"chunk\"\n",
    "# Define the similarity threshold (adjust as needed)\n",
    "similarity_threshold = 0.5\n",
    "\n",
    "query = \"tools for software development\"\n",
    "# Extract the embedding vector\n",
    "embedding = openai.Embedding.create(input=query, engine=AZURE_OPENAI_EMBEDDING_DEPLOYMENT, deployment =AZURE_OPENAI_EMBEDDING_DEPLOYMENT)\n",
    "query_vector = embedding[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the query vector\n",
    "#query_vector=get_embedding(query, engine = AZURE_OPENAI_EMBEDDING_DEPLOYMENT)##\"text-embedding-ada-002\" \n",
    "\n",
    "query = f'''\n",
    "    SELECT t1.chunk_content_vector as chunk_content_vector,\n",
    "           t2.chunk_content as chunk_content\n",
    "    FROM {table_schema}.{table_name} t1\n",
    "    LIMIT 1;\n",
    "'''\n",
    "print(\"Query table\")\n",
    "\n",
    "# Fetch and process the results\n",
    "query = cursor.fetchall()\n",
    "\n",
    "# Function to calculate Euclidean distance between two vectors\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.linalg.norm(np.array(vector1) - np.array(vector2))\n",
    "\n",
    "# Iterate through the results and calculate the Euclidean distance\n",
    "for row in query:\n",
    "    vector1 = row[0]\n",
    "    distance = euclidean_distance(vector1, query_vector)\n",
    "\n",
    "    # Check if the distance is below the threshold\n",
    "    if distance < similarity_threshold:\n",
    "        similar_pairs.append((row[0], vector1, distance))\n",
    "\n",
    "# Print similar pairs\n",
    "#for chunk_content, chunk_content_vector, distance in similar_pairs:\n",
    "#    print(f\"Chunk Content: {chunk_content}\")\n",
    "#    print(f\"Chunk Content Vector: {chunk_content_vector}\")\n",
    "#    print(f\"Euclidean Distance: {distance}\\n\")\n",
    "\n",
    "# Close the PostgreSQL connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
