{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "aoai_endpoint  = os.getenv(\"AOAI_ENDPOINT\")\n",
    "if aoai_endpoint is None or aoai_endpoint == \"\":\n",
    "    print(\"AOAI_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_api_version  = os.getenv(\"AOAI_API_VERSION\")\n",
    "if aoai_api_version is None or aoai_api_version == \"\":\n",
    "    print(\"AOAI_API_VERSION environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_embedding_deployed_model  = os.getenv(\"AOAI_EMBEDDING_DEPLOYED_MODEL\")\n",
    "if aoai_embedding_deployed_model is None or aoai_embedding_deployed_model == \"\":\n",
    "    print(\"AOAI_EMBEDDING_DEPLOYED_MODEL environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "aoai_key  = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "if aoai_key is None or aoai_key == \"\":\n",
    "    print(\"AZURE_OPENAI_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_endpoint  = os.getenv(\"COM_VISION_ENDPOINT\")\n",
    "if com_vision_endpoint is None or com_vision_endpoint == \"\":\n",
    "    print(\"COM_VISION_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_api_version  = os.getenv(\"COM_VISION_API_VERSION\")\n",
    "if com_vision_api_version is None or com_vision_api_version == \"\":\n",
    "    print(\"COM_VISION_API_VERSION environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "com_vision_key  = os.getenv(\"COMPUTER_VISION_KEY\")\n",
    "if com_vision_key is None or com_vision_key == \"\":\n",
    "    print(\"COMPUTER_VISION_KEY environment variable not set.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def vectorize_text_com_vision(com_vision_endpoint,com_vision_key,query):\n",
    "    vectorize_text_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeText\"  \n",
    "    params = {  \n",
    "        \"api-version\": com_vision_api_version \n",
    "    } \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "    }  \n",
    "    data = {\n",
    "        'text':query\n",
    "    }\n",
    "\n",
    "    response = requests.post(vectorize_text_url, params=params, headers=headers, json=data)\n",
    "    query_vector = response.json()[\"vector\"]\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_oai_client = AzureOpenAI(\n",
    "  api_key = aoai_key,  \n",
    "  api_version = aoai_api_version,\n",
    "  azure_endpoint = aoai_endpoint\n",
    ")\n",
    "\n",
    "df = pd.read_json('../data/text/product_docs.json')\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = aoai_key\n",
    "openai.api_base = aoai_endpoint\n",
    "openai.api_version = aoai_api_version\n",
    "\n",
    "df['title_vector'] = df['title'].apply(lambda x : azure_oai_client.embeddings.create(input = [x], model=aoai_embedding_deployed_model).data[0].embedding) \n",
    "df['content_vector'] = df['content'].apply(lambda x : azure_oai_client.embeddings.create(input = [x], model=aoai_embedding_deployed_model).data[0].embedding) \n",
    "\n",
    "df.to_json('../data/text/product_docs_embeddings.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_oai_client = AzureOpenAI(\n",
    "  api_key = aoai_key,  \n",
    "  api_version = aoai_api_version,\n",
    "  azure_endpoint = aoai_endpoint\n",
    ")\n",
    "\n",
    "pdf_reader = PdfReader('../data/docs/employee_handbook.pdf')\n",
    "pages = [page.extract_text() for page in pdf_reader.pages]\n",
    "text = \" \".join(pages)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(text)\n",
    "df = pd.DataFrame(chunks, columns=[\"chunk_content\"])\n",
    "\n",
    "df['chunk_content_vector'] = df['chunk_content'].apply(lambda x : azure_oai_client.embeddings.create(input = [x], model=aoai_embedding_deployed_model).data[0].embedding) \n",
    "df['id'] = df.index\n",
    "df = df[['id', 'chunk_content', 'chunk_content_vector']]\n",
    "\n",
    "df.to_json('../data/docs/employee_handbook_embeddings.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk End-to-End Evaluation Sample Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMBEDDING_FILE_PATH = \"../data/chunking_evaluation/embeddings.json\"\n",
    "\n",
    "CHUNKING_DATA_PATH = \"../data/chunking_evaluation/raw\"\n",
    "GLOB = \"*.md\"\n",
    "\n",
    "# load the documents\n",
    "loader = DirectoryLoader(CHUNKING_DATA_PATH, glob=GLOB, loader_cls=UnstructuredMarkdownLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "# split the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "# embed the documents\n",
    "azure_oai_client = AzureOpenAI(\n",
    "  api_key = aoai_key,\n",
    "  api_version = aoai_api_version,\n",
    "  azure_endpoint = aoai_endpoint\n",
    ")\n",
    "\n",
    "records = []\n",
    "for i, chunk in enumerate(tqdm(chunks)):\n",
    "    chunk_content = chunk.page_content\n",
    "    chunk_content_vector = azure_oai_client.embeddings.create(input = [chunk_content], model=aoai_embedding_deployed_model).data[0].embedding\n",
    "    metadata = chunk.metadata\n",
    "    metadata['source'] = metadata['source'].split(\"/\")[-1]\n",
    "    records.append({\n",
    "        \"id\": str(i),\n",
    "        \"chunk_content\": chunk_content,\n",
    "        \"chunk_content_vector\": chunk_content_vector,\n",
    "        \"metadata\": json.dumps(metadata)\n",
    "    })\n",
    "\n",
    "with open(EMBEDDING_FILE_PATH, \"w\") as f:\n",
    "    json.dump(records, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "image_folder = \"../data/images\"\n",
    "image_list = os.listdir(image_folder)\n",
    "df = pd.DataFrame(columns=['image', 'image_vector'])\n",
    "\n",
    "for image_name in image_list:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "    with open(image_path, \"rb\") as binary_file:\n",
    "        binary_data = binary_file.read()\n",
    "        \n",
    "        vectorize_img_url = f\"{com_vision_endpoint}/computervision/retrieval:vectorizeImage\"  \n",
    "        params = {  \n",
    "            \"api-version\": com_vision_api_version  \n",
    "        } \n",
    "        headers = {  \n",
    "            \"Content-Type\": \"image/jpeg\",  \n",
    "            \"Ocp-Apim-Subscription-Key\": com_vision_key  \n",
    "        }  \n",
    "\n",
    "        response = requests.post(vectorize_img_url, params=params, headers=headers, data=binary_data)\n",
    "\n",
    "        print(response)\n",
    "\n",
    "        df_row = {'image':image_name, 'image_vector':response.json()[\"vector\"]}\n",
    "        df = pd.concat([df, pd.DataFrame([df_row])], ignore_index=True)\n",
    "\n",
    "df['id'] = df.index\n",
    "df = df[['id', 'image', 'image_vector']]\n",
    "\n",
    "df.to_json('../data/images/images_embeddings.json', orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
