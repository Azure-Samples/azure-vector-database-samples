{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline - Cosmos DB Mongo vCore\n",
    "\n",
    "### Prerequisites\n",
    "  \n",
    "- Generate embeddings - [generate_embeddings.ipynb](../../common/generate_embeddings.ipynb) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_env_var(name):\n",
    "    value = os.getenv(name)\n",
    "    if value is None or value == \"\":\n",
    "        print(f\"{name} environment variable not set.\")\n",
    "        exit()\n",
    "    return value\n",
    "\n",
    "\n",
    "mongo_clustername = get_env_var(\"MONGO_CLUSTERNAME\")\n",
    "mongo_username = get_env_var(\"MONGO_USERNAME\")\n",
    "mongo_password = get_env_var(\"MONGO_PASSWORD\")\n",
    "\n",
    "text_index_name = \"text-sample\"\n",
    "doc_index_name = \"doc-sample\"\n",
    "image_index_name = \"image-sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pymongo\n",
    "from pymongo.errors import ConnectionFailure\n",
    "\n",
    "conn_str = f\"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_clustername}.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000\"\n",
    "\n",
    "\n",
    "def get_mongo_client():\n",
    "    return pymongo.MongoClient(conn_str)\n",
    "\n",
    "\n",
    "try:\n",
    "    client = get_mongo_client()\n",
    "except ConnectionFailure():\n",
    "    print(\"Server not available\")\n",
    "\n",
    "# TODO: use private endpoint around mongo to avoid need to add ClientIPAddress to firewall rules\n",
    "\n",
    "client.admin.command(\"ping\")\n",
    "\n",
    "\n",
    "def ivf_numlists(length):\n",
    "    # calculate number of lists for an IVF index\n",
    "\n",
    "    if length < 1000000:\n",
    "        num_lists = length // 1000\n",
    "\n",
    "        if length % 1000 != 0:\n",
    "            num_lists += 1\n",
    "        return num_lists\n",
    "\n",
    "    else:\n",
    "        num_lists = math.isqrt(length)\n",
    "\n",
    "        return num_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create text-sample Mongo index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "text_df = pd.read_json(\"../data/text/product_docs_embeddings.json\")\n",
    "\n",
    "records = text_df.to_dict(\"records\")\n",
    "\n",
    "client = get_mongo_client()\n",
    "\n",
    "db = client.semanticsearch\n",
    "\n",
    "# Create a collection\n",
    "collection = db.text\n",
    "\n",
    "# Prepare bulk upsert operations\n",
    "operations = [\n",
    "    UpdateOne({\"_id\": doc[\"id\"]}, {\"$set\": doc}, upsert=True) for doc in records\n",
    "]\n",
    "\n",
    "# Execute bulk upsert\n",
    "collection.bulk_write(operations)\n",
    "\n",
    "num_lists = ivf_numlists(len(records))\n",
    "\n",
    "# db.text.drop_index(\"text_vector_index\")\n",
    "\n",
    "# Create Vector Index using IVF (Inverted File Index)\n",
    "db.command(\n",
    "    {\n",
    "        \"createIndexes\": \"text\",\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": \"text_vector_index\",\n",
    "                \"key\": {\"title_vector\": \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-ivf\",\n",
    "                    \"numLists\": num_lists,\n",
    "                    \"similarity\": \"COS\",\n",
    "                    \"dimensions\": 1536,  # 1536 for OpenAI ADA model embeddings\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create doc-sample Mongo index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "doc_df = pd.read_json(\"../data/docs/employee_handbook_embeddings.json\")\n",
    "\n",
    "records = doc_df.to_dict(\"records\")\n",
    "\n",
    "client = get_mongo_client()\n",
    "\n",
    "db = client.semanticsearch\n",
    "\n",
    "# Create a collection\n",
    "collection = db.docs\n",
    "\n",
    "# Prepare bulk upsert operations\n",
    "operations = [\n",
    "    UpdateOne({\"_id\": doc[\"id\"]}, {\"$set\": doc}, upsert=True) for doc in records\n",
    "]\n",
    "\n",
    "# Execute bulk upsert\n",
    "collection.bulk_write(operations)\n",
    "\n",
    "num_lists = ivf_numlists(len(records))\n",
    "\n",
    "# db.docs.drop_index(\"docs_vector_index\")\n",
    "\n",
    "# Create Vector Index using IVF (Inverted File Index)\n",
    "db.command(\n",
    "    {\n",
    "        \"createIndexes\": \"docs\",\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": \"docs_vector_index\",\n",
    "                \"key\": {\"chunk_content_vector\": \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-ivf\",\n",
    "                    \"numLists\": num_lists,\n",
    "                    \"similarity\": \"COS\",\n",
    "                    \"dimensions\": 1536,  # 1536 for OpenAI ADA model embeddings\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create image-sample Mongo index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "doc_df = pd.read_json(\"../data/images/images_embeddings.json\")\n",
    "\n",
    "records = doc_df.to_dict(\"records\")\n",
    "\n",
    "client = get_mongo_client()\n",
    "\n",
    "db = client.semanticsearch\n",
    "\n",
    "# Create a collection\n",
    "collection = db.images\n",
    "\n",
    "# Prepare bulk upsert operations\n",
    "operations = [\n",
    "    UpdateOne({\"_id\": doc[\"id\"]}, {\"$set\": doc}, upsert=True) for doc in records\n",
    "]\n",
    "\n",
    "# Execute bulk upsert\n",
    "collection.bulk_write(operations)\n",
    "\n",
    "num_lists = ivf_numlists(len(records))\n",
    "\n",
    "# db.images.drop_index(\"images_vector_index\")\n",
    "\n",
    "# Create Vector Index using IVF (Inverted File Index)\n",
    "db.command(\n",
    "    {\n",
    "        \"createIndexes\": \"images\",\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": \"images_vector_index\",\n",
    "                \"key\": {\"image_vector\": \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-ivf\",\n",
    "                    \"numLists\": num_lists,\n",
    "                    \"similarity\": \"COS\",\n",
    "                    \"dimensions\": 1024,  # 1024 for Azure Computer Vision Service embeddings\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
