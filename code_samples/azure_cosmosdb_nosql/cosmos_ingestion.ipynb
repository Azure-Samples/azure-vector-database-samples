{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ingestion to Azure Cosmos DB NoSQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pip \n",
    "##### (Optional: As you can use requirements.txt or Yml if you prefer, instead the pip install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##You can also use the requirements.txt or yml file.\n",
    "! pip install numpy\n",
    "! pip install python-dotenv\n",
    "! pip install azure-core \n",
    "! pip install azure-cosmos\n",
    "! pip install tenacity\n",
    "! pip install azure-search-documents===11.4.0\n",
    "! pip install pandas\n",
    "! pip install openai==0.28.1\n",
    "! pip install matplotlib\n",
    "! pip install plotly\n",
    "! pip install plotly\n",
    "! pip install scikit-learn\n",
    "! pip install scipy\n",
    "! pip install Pyarrow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    IndexingSchedule,\n",
    "    SemanticSearch, \n",
    "    SemanticPrioritizedFields,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SemanticConfiguration,\n",
    "    SimpleField,\n",
    "    SemanticField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchProfile,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters\n",
    ")\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "import pandas as pd\n",
    "from azure.cosmos import CosmosClient, partition_key, exceptions\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enviroment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "## Cosmos db endpoint format: https://<nameofyourcosmosservice>.documents.azure.com\n",
    "cosmos_db_api_endpoint  = os.getenv(\"cosmos_db_api_endpoint\")\n",
    "if cosmos_db_api_endpoint is None or cosmos_db_api_endpoint == \"\":\n",
    "    print(\"cosmos_db_api_endpoint environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "## Cosmos db API Key\n",
    "cosmos_db_api_key  = os.getenv(\"cosmos_db_api_key\")\n",
    "if cosmos_db_api_key is None or cosmos_db_api_key == \"\":\n",
    "    print(\"cosmos_db_api_key environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Cosmos Connection String. Format: \n",
    "##AccountEndpoint=https://<nameofthesevice>.documents.azure.com;AccountKey=<value of the key>;Database=<name of the database, suggested here Vector_DB>;\n",
    "cosmos_db_connection_string  = os.getenv(\"cosmos_db_connection_string\")\n",
    "if cosmos_db_connection_string is None or cosmos_db_connection_string == \"\":\n",
    "    print(\"cosmos_db_connection_string environment variable not set.\")\n",
    "    exit()\n",
    "    \n",
    "##Cognitive Search Service Name, you need to deploy this service. Format: https://<nameoftheservice>.search.windows.net\n",
    "cog_search_endpoint  = os.getenv(\"cog_search_endpoint\")\n",
    "if cog_search_endpoint is None or cog_search_endpoint == \"\":\n",
    "    print(\"cog_search_endpoint environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Cognitive Search Service Key\n",
    "cog_search_key  = os.getenv(\"cog_search_key\")\n",
    "if cog_search_key is None or cog_search_key == \"\":\n",
    "    print(\"cog_search_key environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "    \n",
    "##Open AI Service. This must be deployed. Format:https://nameoftheservice.azure.com/    \n",
    "aoai_endpoint  = os.getenv(\"AOAI_ENDPOINT\") ##api_base \n",
    "if aoai_endpoint is None or aoai_endpoint == \"\":\n",
    "    print(\"AOAI_ENDPOINT environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Version of the Open AI Service. This was build with the \"2023-05-15\" version\n",
    "aoai_api_version  = os.getenv(\"AOAI_API_VERSION\")\n",
    "if aoai_api_version is None or aoai_api_version == \"\":\n",
    "    print(\"AOAI_API_VERSION environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Model  of the Open AI Service. This must be deployed: \"text-embedding-ada-002\"\n",
    "aoai_embedding_deployed_model  = os.getenv(\"AOAI_EMBEDDING_DEPLOYED_MODEL\")\n",
    "if aoai_embedding_deployed_model is None or aoai_embedding_deployed_model == \"\":\n",
    "    print(\"AOAI_EMBEDDING_DEPLOYED_MODEL environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Open AI ServikeyKeyce.\n",
    "azure_openai_key  = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "if azure_openai_key is None or azure_openai_key == \"\":\n",
    "    print(\"AZURE_OPENAI_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "##Container names for the CosmosDB\n",
    "text_table_name = 'text_sample'\n",
    "doc_table_name = 'doc_sample'\n",
    "image_table_name = 'image_sample'\n",
    "\n",
    "database_name = \"Vector_DB\"\n",
    "credential = AzureKeyCredential(str(cog_search_key))\n",
    "openai.api_type = \"azure\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmos ( Nosql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "\n",
    "# Initialize the Cosmos DB client\n",
    "client = CosmosClient(cosmos_db_api_endpoint, credential=cosmos_db_api_key)\n",
    "\n",
    "# Create or get a reference to the database\n",
    "database = client.create_database_if_not_exists(id=database_name)\n",
    "\n",
    "print(f\"Database {database_name} created or retrieved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Initialize the Cosmos DB client - Creating containers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for the New Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## this adaptation, the script uses the Cosmos DB Python SDK to create items in the Cosmos DB container. \n",
    "# Function to insert data into Cosmos DB\n",
    "def new_container(container):\n",
    "    try:\n",
    "        partition_key_ = PartitionKey(path=\"/id\")\n",
    "        container = database.create_container_if_not_exists(\n",
    "        id=container,\n",
    "        partition_key=partition_key_   )\n",
    "\n",
    "        print(f\"Document {container} created successfully\")\n",
    "\n",
    "    except exceptions.CosmosResourceExistsError as e:\n",
    "            print(\"Container already exists.\")\n",
    "\n",
    "    except Exception as e:\n",
    "            # Handle other exceptions\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Text ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cosmosdb_container_name = text_table_name\n",
    "container = database.get_container_client(cosmosdb_container_name)\n",
    "\n",
    "# Read data from the JSON file\n",
    "text_df = pd.read_json('../data/text/product_docs_embeddings.json')\n",
    "records = text_df.to_dict(orient='records')\n",
    "\n",
    "\n",
    "# Create cntainer\n",
    "new_container(cosmosdb_container_name)\n",
    "\n",
    "\n",
    "# Iterate through the data and insert the files with the embeddings into the container\n",
    "try:\n",
    "    for item in records:\n",
    "        title = item['title']\n",
    "        content = item['content']\n",
    "        item['title_vector'] = item['title_vector']\n",
    "        item['content_vector'] = item['content_vector']\n",
    "        item['@search.action'] = 'upload'\n",
    "\n",
    "        # Convert the 'id' attribute to a string\n",
    "        item['id'] = str(item['id'])\n",
    "\n",
    "        # Insert the item into the container\n",
    "        container.create_item(body=item)\n",
    "\n",
    "    print(f\"Data items inserted into the Cosmos DB {cosmosdb_container_name}\")\n",
    "\n",
    "except exceptions.CosmosResourceExistsError as e:\n",
    "    # Handle conflict error\n",
    "    print(f\"Document {container} with ID {item['id']} already exists...\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle other exceptions\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Doc ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmosdb_container_name = doc_table_name\n",
    "container = database.get_container_client(cosmosdb_container_name)\n",
    "\n",
    "# Read data from the JSON file\n",
    "doc_df = pd.read_json('../data/docs/employee_handbook_embeddings.json')\n",
    "records = doc_df.to_dict(orient='records')\n",
    "\n",
    "# Create cntainer\n",
    "new_container(cosmosdb_container_name)\n",
    "\n",
    "# Iterate through the data and insert the files with the embeddings into the container\n",
    "try:\n",
    "    for item in records:\n",
    "        chunk_content = item['chunk_content']\n",
    "        item['chunk_content_vector'] = item['chunk_content_vector']\n",
    "        item['@search.action'] = 'upload'\n",
    "\n",
    "        # Convert the 'id' attribute to a string\n",
    "        item['id'] = str(item['id'])\n",
    "\n",
    "        # Insert the item into the container\n",
    "        container.create_item(body=item)\n",
    "\n",
    "    print(f\"Data items inserted into the Cosmos DB {cosmosdb_container_name}\")\n",
    "\n",
    "except exceptions.CosmosResourceExistsError as e:\n",
    "    # Handle conflict error\n",
    "    print(f\"Document {container} with ID {item['id']} already exists...\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle other exceptions\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the data inserted (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the container name\n",
    "Table_name = \"text_sample\"\n",
    "container = database.get_container_client(Table_name)\n",
    "\n",
    "#Number of rows - Top 10 for example\n",
    "top_x_rows = 10\n",
    "\n",
    "print(f\"Quality test  top ( {top_x_rows} )\")\n",
    "\n",
    "query = f\"SELECT TOP {top_x_rows} * FROM c\"\n",
    "\n",
    "# Execute the query\n",
    "query_result = container.query_items(query, enable_cross_partition_query=True)\n",
    "\n",
    "# Process the query result\n",
    "for item in query_result:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create HSNW Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vector search configuration\n",
    "##adding profiles as there is a change in this library. Note using Azure Search documents 11.4.0\n",
    "vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"hsnw_config\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE\n",
    "    )\n",
    "            ),\n",
    "            ExhaustiveKnnAlgorithmConfiguration(\n",
    "                name=\"ExhaustiveKnn\",\n",
    "                kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "                parameters=ExhaustiveKnnParameters(\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"HnswProfile\",\n",
    "                algorithm_configuration_name=\"hsnw_config\",\n",
    "            ),\n",
    "            VectorSearchProfile(\n",
    "                name=\"myExhaustiveKnnProfile\",\n",
    "                algorithm_configuration_name=\"ExhaustiveKnn\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    index_client = SearchIndexClient(endpoint=cog_search_endpoint, credential=credential)\n",
    "\n",
    "\n",
    "    # Define index fields for text_sample\n",
    "    text_index_name = \"text_sample_index\"\n",
    "    text_fields = [\n",
    "            SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "            SearchableField(name=\"title\", type=SearchFieldDataType.String, searchable=True, retrievable=True),\n",
    "            SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True, retrievable=True),\n",
    "            SearchableField(name=\"category\", type=SearchFieldDataType.String, filterable=True, searchable=True, retrievable=True),\n",
    "            # Ensure dimensions and vectorSearchConfiguration are set for title_vector\n",
    "        SearchField(name=\"title_vector\",\n",
    "                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  # Change the type to Collection(Edm.String)\n",
    "                searchable=True, \n",
    "                vector_search_dimensions=1536,  # Adjust dimensions as needed\n",
    "                vector_search_profile_name=\"HnswProfile\"),\n",
    "\n",
    "        SearchField(name=\"content_vector\",\n",
    "                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  # Change the type to Collection(Edm.String)\n",
    "                searchable=True, \n",
    "                vector_search_dimensions=1536,  # Adjust dimensions as needed\n",
    "                vector_search_profile_name=\"HnswProfile\"),\n",
    "\n",
    "        ]\n",
    "  \n",
    "    # Define index fields for doc_sample\n",
    "    doc_index_name = \"doc_sample_index\"\n",
    "    doc_fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"chunk_content\", type=SearchFieldDataType.Single,\n",
    "                        searchable=True, retrievable=True),\n",
    "        SearchField(name=\"chunk_content_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  # Change the type to Collection(Edm.String)\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=1536,  # Adjust dimensions as needed\n",
    "            vector_search_profile_name=\"HnswProfile\"),\n",
    "       \n",
    "    ]\n",
    "\n",
    "\n",
    "    # Semantic search configuration\n",
    "    config_text = SemanticConfiguration(\n",
    "        name=\"ConfigSemantictext\",\n",
    "        prioritized_fields=SemanticPrioritizedFields (\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "            content_fields=[SemanticField(field_name=\"content\")]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    config_doc = SemanticConfiguration(\n",
    "        name=\"ConfigSemanticdoc\",\n",
    "        prioritized_fields=SemanticPrioritizedFields (\n",
    "            title_field=SemanticField(field_name=\"chunk_content\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create the configurration\n",
    "    settings_text = SemanticSearch(configurations=[config_text])\n",
    "    settings_doc = SemanticSearch(configurations=[config_doc])\n",
    "\n",
    "    \n",
    "    # Create indexes\n",
    "    text_index = SearchIndex(name=text_index_name, fields=text_fields, vector_search=vector_search,semantic_search= settings_text)\n",
    "    doc_index = SearchIndex(name=doc_index_name, fields=doc_fields, vector_search=vector_search,semantic_search= settings_doc)\n",
    "\n",
    "\n",
    "\n",
    "    # Create or update indexes\n",
    "    index_client.create_or_update_index(text_index)\n",
    "    print(f'Indexes created or updated: {text_index_name}')\n",
    "    index_client.create_or_update_index(doc_index)\n",
    "    print(f'Indexes created or updated: {doc_index_name}')\n",
    "    \n",
    "except HttpResponseError as e:\n",
    "    print(f\"HTTP Error: {e}\")\n",
    "    print(f\"Status Code: {e.status_code}\")\n",
    "    print(f\"Error Message: {e.error.message}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Azure Cognitve search index\n",
    "##### Datsource Function\n",
    "##### Indexer Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_datasource(data_source_name, cosmos_db_connection_string, table_name, indexer_client):\n",
    "    try:\n",
    "        container_cosmos = SearchIndexerDataContainer(\n",
    "            name=table_name,\n",
    "            query=f\"SELECT * FROM {table_name} c WHERE c._ts>@HighWaterMark ORDER BY  c._ts\"\n",
    "        )\n",
    "\n",
    "        # Define the data source connection\n",
    "        data_source_connection = SearchIndexerDataSourceConnection(\n",
    "            name=data_source_name,\n",
    "            type=\"cosmosdb\",\n",
    "            connection_string=cosmos_db_connection_string,\n",
    "            container=container_cosmos\n",
    "        )\n",
    "\n",
    "        # Create or update the data source connection\n",
    "        data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "    except HttpResponseError as ex:\n",
    "        print(f\"Error: {ex}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexer_if_not_exists(\n",
    "    indexer_name, target_index_name, data_source_name, indexer_client\n",
    "\n",
    "):\n",
    "\n",
    "    try:\n",
    "      \n",
    "            # Create and run the indexer\n",
    "            indexer = SearchIndexer(\n",
    "                name=indexer_name,\n",
    "                data_source_name=data_source_name,\n",
    "                target_index_name=target_index_name\n",
    "            )\n",
    "\n",
    "            indexer_client.create_or_update_indexer(indexer)\n",
    "            indexer_client.run_indexer(indexer_name)\n",
    "\n",
    "    except HttpResponseError as ex:\n",
    "        print(f\"Error: {ex}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the datasource and index from the functions already defined\n",
    "##### Indexers to crawl data from the data source and insert them into the indexes\n",
    "##### Data Source that connect Azure Cognitive Search to Cosmos NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##You must have a Cognitve search service already created\n",
    "indexer_client = SearchIndexerClient(cog_search_endpoint, credential)\n",
    "\n",
    "\n",
    "data_source_name = 'textsample'\n",
    "table_name =text_table_name\n",
    "indexer_name = data_source_name\n",
    "target_index_name_=text_index_name\n",
    "\n",
    "create_datasource(data_source_name,cosmos_db_connection_string,table_name, indexer_client)\n",
    "create_indexer_if_not_exists(indexer_name, target_index_name_, data_source_name, indexer_client)\n",
    "\n",
    "\n",
    "data_source_name = 'docsample'\n",
    "table_name =doc_table_name\n",
    "indexer_name = data_source_name\n",
    "target_index_name_=doc_index_name\n",
    "\n",
    "create_datasource(data_source_name,cosmos_db_connection_string,table_name, indexer_client)\n",
    "create_indexer_if_not_exists(indexer_name, target_index_name_, data_source_name,indexer_client)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgresql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
